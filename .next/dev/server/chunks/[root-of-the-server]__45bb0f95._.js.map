{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 46, "column": 0}, "map": {"version":3,"sources":["file:///Users/wearebrain/Desktop/Manglar%20Media/adv_builder/xevio-adv-builder/app/api/scrape/route.ts"],"sourcesContent":["import { NextResponse } from 'next/server'\nimport { createClient } from '@supabase/supabase-js'\n\ninterface ScrapeRequestBody {\n  stepOneData: {\n    topic: string\n    campaignType: string\n    niche: string\n    country: string\n    language: string\n    length: string\n    paragraphLength: string\n    guidelines: string\n    customGuidelines?: string\n  }\n  stepTwoData: {\n    referenceUrls: Array<{ url: string; description?: string } | string>\n  }\n  userId: string\n  campaignId?: string        // Existing campaign to update\n  newUrlsOnly?: string[]     // Only scrape these URLs (incremental)\n  isFullRescrape?: boolean   // Clear existing results first\n}\n\nexport async function POST(request: Request) {\n  try {\n    const body: ScrapeRequestBody = await request.json()\n    const { stepOneData, stepTwoData, userId, campaignId, newUrlsOnly, isFullRescrape } = body\n\n    // 1. Validate data\n    const validUrls = stepTwoData?.referenceUrls?.filter((ref: any) => {\n      const url = typeof ref === 'string' ? ref : ref?.url\n      return url && url.trim() !== ''\n    }) || []\n    \n    if (validUrls.length === 0) {\n      return NextResponse.json({ error: 'No reference URLs provided' }, { status: 400 })\n    }\n\n    // 2. Initialize Supabase client\n    const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!\n    const supabaseKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!\n    const supabase = createClient(supabaseUrl, supabaseKey)\n\n    // Prepare URLs with descriptions\n    const urlsWithContext = validUrls.map((ref: any) => {\n      if (typeof ref === 'string') {\n        return { url: ref.trim(), description: null }\n      }\n      return { \n        url: ref.url.trim(), \n        description: ref.description?.trim() || null \n      }\n    })\n\n    let finalCampaignId: string\n    let existingInsights: any = null\n\n    // 3. Handle different scraping modes\n    if (campaignId && !isFullRescrape && newUrlsOnly && newUrlsOnly.length > 0) {\n      // INCREMENTAL SCRAPE: Only scrape new URLs and append to existing\n      \n      // Fetch existing campaign to get current scraping_result\n      const { data: existingCampaign, error: fetchError } = await supabase\n        .from('campaigns')\n        .select('scraping_result')\n        .eq('id', campaignId)\n        .single()\n      \n      if (fetchError) {\n        console.error('Error fetching existing campaign:', fetchError)\n        return NextResponse.json({ error: 'Failed to fetch existing campaign' }, { status: 500 })\n      }\n      \n      existingInsights = existingCampaign?.scraping_result || null\n\n      // Update campaign with new URLs and set status to scraping\n      const { error: updateError } = await supabase\n        .from('campaigns')\n        .update({\n          reference_urls: urlsWithContext,\n          status: 'scraping',\n          // Update Step 1 data in case it changed (though for incremental it shouldn't)\n          topic: stepOneData.topic,\n          campaign_type: stepOneData.campaignType,\n          niche: stepOneData.niche,\n          country: stepOneData.country,\n          language: stepOneData.language,\n          length: stepOneData.length,\n          paragraph_length: stepOneData.paragraphLength,\n          guidelines: stepOneData.guidelines,\n        })\n        .eq('id', campaignId)\n\n      if (updateError) {\n        console.error('Supabase Update Error:', updateError)\n        return NextResponse.json({ error: 'Failed to update campaign' }, { status: 500 })\n      }\n\n      finalCampaignId = campaignId\n\n    } else if (campaignId && isFullRescrape) {\n      // FULL RE-SCRAPE: Clear existing results and scrape all URLs again\n      \n      const { error: updateError } = await supabase\n        .from('campaigns')\n        .update({\n          reference_urls: urlsWithContext,\n          scraping_result: null, // Clear existing results\n          status: 'scraping',\n          // Update Step 1 data\n          topic: stepOneData.topic,\n          campaign_type: stepOneData.campaignType,\n          niche: stepOneData.niche,\n          country: stepOneData.country,\n          language: stepOneData.language,\n          length: stepOneData.length,\n          paragraph_length: stepOneData.paragraphLength,\n          guidelines: stepOneData.guidelines,\n        })\n        .eq('id', campaignId)\n\n      if (updateError) {\n        console.error('Supabase Update Error:', updateError)\n        return NextResponse.json({ error: 'Failed to update campaign' }, { status: 500 })\n      }\n\n      finalCampaignId = campaignId\n\n    } else {\n      // NEW CAMPAIGN: Create fresh campaign record\n      \n      const { data: campaign, error: dbError } = await supabase\n        .from('campaigns')\n        .insert({\n          user_id: userId,\n          topic: stepOneData.topic,\n          campaign_type: stepOneData.campaignType,\n          niche: stepOneData.niche,\n          country: stepOneData.country,\n          language: stepOneData.language,\n          length: stepOneData.length,\n          paragraph_length: stepOneData.paragraphLength,\n          guidelines: stepOneData.guidelines,\n          reference_urls: urlsWithContext,\n          status: 'scraping'\n        })\n        .select()\n        .single()\n\n      if (dbError) {\n        console.error('Supabase Error:', dbError)\n        return NextResponse.json({ error: 'Failed to create campaign' }, { status: 500 })\n      }\n\n      finalCampaignId = campaign.id\n    }\n\n    // 4. Trigger n8n Webhook\n    const n8nWebhookUrl = process.env.N8N_SCRAPE_WEBHOOK_URL\n    const n8nWebhookSecret = process.env.N8N_WEBHOOK_SECRET\n    \n    if (n8nWebhookUrl) {\n      const headers: Record<string, string> = { 'Content-Type': 'application/json' }\n      if (n8nWebhookSecret) {\n        headers['X-Webhook-Secret'] = n8nWebhookSecret\n      }\n\n      // Determine which URLs to send to n8n\n      const urlsToScrape = newUrlsOnly && newUrlsOnly.length > 0\n        ? urlsWithContext.filter(u => newUrlsOnly.includes(u.url.toLowerCase().replace(/\\/+$/, '')))\n        : urlsWithContext\n\n      // Determine scraping mode for n8n\n      const mode = (newUrlsOnly && newUrlsOnly.length > 0 && !isFullRescrape) \n        ? 'incremental' \n        : 'full'\n\n      // Fire-and-forget: Trigger n8n webhook without blocking the API response\n      // This allows the user to proceed immediately while scraping happens in background\n      fetch(n8nWebhookUrl, {\n        method: 'POST',\n        headers: headers,\n        body: JSON.stringify({\n          campaignId: finalCampaignId,\n          urls: urlsToScrape,\n          mode: mode,\n          // Include existing insights for incremental mode so n8n can merge\n          existingInsights: mode === 'incremental' ? existingInsights : null,\n          context: {\n            topic: stepOneData.topic,\n            niche: stepOneData.niche,\n            campaignType: stepOneData.campaignType,\n            country: stepOneData.country,\n            language: stepOneData.language,\n            guidelines: stepOneData.guidelines\n          }\n        })\n      }).catch((error) => {\n        // Log error but don't block - scraping will be retried if needed\n        console.error('Failed to trigger n8n webhook:', error)\n      })\n    } else {\n      console.warn('N8N_SCRAPE_WEBHOOK_URL is not defined')\n    }\n\n    return NextResponse.json({ success: true, campaignId: finalCampaignId })\n\n  } catch (error) {\n    console.error('API Error:', error)\n    return NextResponse.json({ error: 'Internal Server Error' }, { status: 500 })\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;;;AAuBO,eAAe,KAAK,OAAgB;IACzC,IAAI;QACF,MAAM,OAA0B,MAAM,QAAQ,IAAI;QAClD,MAAM,EAAE,WAAW,EAAE,WAAW,EAAE,MAAM,EAAE,UAAU,EAAE,WAAW,EAAE,cAAc,EAAE,GAAG;QAEtF,mBAAmB;QACnB,MAAM,YAAY,aAAa,eAAe,OAAO,CAAC;YACpD,MAAM,MAAM,OAAO,QAAQ,WAAW,MAAM,KAAK;YACjD,OAAO,OAAO,IAAI,IAAI,OAAO;QAC/B,MAAM,EAAE;QAER,IAAI,UAAU,MAAM,KAAK,GAAG;YAC1B,OAAO,gJAAY,CAAC,IAAI,CAAC;gBAAE,OAAO;YAA6B,GAAG;gBAAE,QAAQ;YAAI;QAClF;QAEA,gCAAgC;QAChC,MAAM;QACN,MAAM;QACN,MAAM,WAAW,IAAA,gMAAY,EAAC,aAAa;QAE3C,iCAAiC;QACjC,MAAM,kBAAkB,UAAU,GAAG,CAAC,CAAC;YACrC,IAAI,OAAO,QAAQ,UAAU;gBAC3B,OAAO;oBAAE,KAAK,IAAI,IAAI;oBAAI,aAAa;gBAAK;YAC9C;YACA,OAAO;gBACL,KAAK,IAAI,GAAG,CAAC,IAAI;gBACjB,aAAa,IAAI,WAAW,EAAE,UAAU;YAC1C;QACF;QAEA,IAAI;QACJ,IAAI,mBAAwB;QAE5B,qCAAqC;QACrC,IAAI,cAAc,CAAC,kBAAkB,eAAe,YAAY,MAAM,GAAG,GAAG;YAC1E,kEAAkE;YAElE,yDAAyD;YACzD,MAAM,EAAE,MAAM,gBAAgB,EAAE,OAAO,UAAU,EAAE,GAAG,MAAM,SACzD,IAAI,CAAC,aACL,MAAM,CAAC,mBACP,EAAE,CAAC,MAAM,YACT,MAAM;YAET,IAAI,YAAY;gBACd,QAAQ,KAAK,CAAC,qCAAqC;gBACnD,OAAO,gJAAY,CAAC,IAAI,CAAC;oBAAE,OAAO;gBAAoC,GAAG;oBAAE,QAAQ;gBAAI;YACzF;YAEA,mBAAmB,kBAAkB,mBAAmB;YAExD,2DAA2D;YAC3D,MAAM,EAAE,OAAO,WAAW,EAAE,GAAG,MAAM,SAClC,IAAI,CAAC,aACL,MAAM,CAAC;gBACN,gBAAgB;gBAChB,QAAQ;gBACR,8EAA8E;gBAC9E,OAAO,YAAY,KAAK;gBACxB,eAAe,YAAY,YAAY;gBACvC,OAAO,YAAY,KAAK;gBACxB,SAAS,YAAY,OAAO;gBAC5B,UAAU,YAAY,QAAQ;gBAC9B,QAAQ,YAAY,MAAM;gBAC1B,kBAAkB,YAAY,eAAe;gBAC7C,YAAY,YAAY,UAAU;YACpC,GACC,EAAE,CAAC,MAAM;YAEZ,IAAI,aAAa;gBACf,QAAQ,KAAK,CAAC,0BAA0B;gBACxC,OAAO,gJAAY,CAAC,IAAI,CAAC;oBAAE,OAAO;gBAA4B,GAAG;oBAAE,QAAQ;gBAAI;YACjF;YAEA,kBAAkB;QAEpB,OAAO,IAAI,cAAc,gBAAgB;YACvC,mEAAmE;YAEnE,MAAM,EAAE,OAAO,WAAW,EAAE,GAAG,MAAM,SAClC,IAAI,CAAC,aACL,MAAM,CAAC;gBACN,gBAAgB;gBAChB,iBAAiB;gBACjB,QAAQ;gBACR,qBAAqB;gBACrB,OAAO,YAAY,KAAK;gBACxB,eAAe,YAAY,YAAY;gBACvC,OAAO,YAAY,KAAK;gBACxB,SAAS,YAAY,OAAO;gBAC5B,UAAU,YAAY,QAAQ;gBAC9B,QAAQ,YAAY,MAAM;gBAC1B,kBAAkB,YAAY,eAAe;gBAC7C,YAAY,YAAY,UAAU;YACpC,GACC,EAAE,CAAC,MAAM;YAEZ,IAAI,aAAa;gBACf,QAAQ,KAAK,CAAC,0BAA0B;gBACxC,OAAO,gJAAY,CAAC,IAAI,CAAC;oBAAE,OAAO;gBAA4B,GAAG;oBAAE,QAAQ;gBAAI;YACjF;YAEA,kBAAkB;QAEpB,OAAO;YACL,6CAA6C;YAE7C,MAAM,EAAE,MAAM,QAAQ,EAAE,OAAO,OAAO,EAAE,GAAG,MAAM,SAC9C,IAAI,CAAC,aACL,MAAM,CAAC;gBACN,SAAS;gBACT,OAAO,YAAY,KAAK;gBACxB,eAAe,YAAY,YAAY;gBACvC,OAAO,YAAY,KAAK;gBACxB,SAAS,YAAY,OAAO;gBAC5B,UAAU,YAAY,QAAQ;gBAC9B,QAAQ,YAAY,MAAM;gBAC1B,kBAAkB,YAAY,eAAe;gBAC7C,YAAY,YAAY,UAAU;gBAClC,gBAAgB;gBAChB,QAAQ;YACV,GACC,MAAM,GACN,MAAM;YAET,IAAI,SAAS;gBACX,QAAQ,KAAK,CAAC,mBAAmB;gBACjC,OAAO,gJAAY,CAAC,IAAI,CAAC;oBAAE,OAAO;gBAA4B,GAAG;oBAAE,QAAQ;gBAAI;YACjF;YAEA,kBAAkB,SAAS,EAAE;QAC/B;QAEA,yBAAyB;QACzB,MAAM,gBAAgB,QAAQ,GAAG,CAAC,sBAAsB;QACxD,MAAM,mBAAmB,QAAQ,GAAG,CAAC,kBAAkB;QAEvD,IAAI,eAAe;YACjB,MAAM,UAAkC;gBAAE,gBAAgB;YAAmB;YAC7E,IAAI,kBAAkB;gBACpB,OAAO,CAAC,mBAAmB,GAAG;YAChC;YAEA,sCAAsC;YACtC,MAAM,eAAe,eAAe,YAAY,MAAM,GAAG,IACrD,gBAAgB,MAAM,CAAC,CAAA,IAAK,YAAY,QAAQ,CAAC,EAAE,GAAG,CAAC,WAAW,GAAG,OAAO,CAAC,QAAQ,QACrF;YAEJ,kCAAkC;YAClC,MAAM,OAAO,AAAC,eAAe,YAAY,MAAM,GAAG,KAAK,CAAC,iBACpD,gBACA;YAEJ,yEAAyE;YACzE,mFAAmF;YACnF,MAAM,eAAe;gBACnB,QAAQ;gBACR,SAAS;gBACT,MAAM,KAAK,SAAS,CAAC;oBACnB,YAAY;oBACZ,MAAM;oBACN,MAAM;oBACN,kEAAkE;oBAClE,kBAAkB,SAAS,gBAAgB,mBAAmB;oBAC9D,SAAS;wBACP,OAAO,YAAY,KAAK;wBACxB,OAAO,YAAY,KAAK;wBACxB,cAAc,YAAY,YAAY;wBACtC,SAAS,YAAY,OAAO;wBAC5B,UAAU,YAAY,QAAQ;wBAC9B,YAAY,YAAY,UAAU;oBACpC;gBACF;YACF,GAAG,KAAK,CAAC,CAAC;gBACR,iEAAiE;gBACjE,QAAQ,KAAK,CAAC,kCAAkC;YAClD;QACF,OAAO;YACL,QAAQ,IAAI,CAAC;QACf;QAEA,OAAO,gJAAY,CAAC,IAAI,CAAC;YAAE,SAAS;YAAM,YAAY;QAAgB;IAExE,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,cAAc;QAC5B,OAAO,gJAAY,CAAC,IAAI,CAAC;YAAE,OAAO;QAAwB,GAAG;YAAE,QAAQ;QAAI;IAC7E;AACF"}}]
}